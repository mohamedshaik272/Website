<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mohamed Shaik - Projects</title>
    <link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic+Coding&family=Aleo:wght@400;700&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <header>
        <nav>
            <a href="index.html">about</a>
            <a href="experience.html">experience</a>
            <div class="nav-name">
                <div class="split-effect" data-text="MS">MS</div>
            </div>
            <a href="projects.html" class="active">projects</a>
            <a href="photography.html">photography</a>
        </nav>
    </header>

    <div class="container">
        <section id="projects" class="section">
            <h1>Projects</h1>
            <div class="project-item">
                <div class="proj-header">
                    <div class="proj-title">Parkinson's Care VR System</div>
                    <div class="proj-links">
                        <a href="https://github.com/mohamedshaik272/Parkinsons-Care-VR-System" target="_blank"
                            class="link-github">github</a>
                        <a href="https://www.canva.com/design/DAGh0KRijR8/oKBFJRbwcBhVm206AKvEqw/edit" target="_blank"
                            class="link-slides">slides</a>
                        <a href="https://www.linkedin.com/feed/update/urn:li:activity:7307214892233572353/"
                            target="_blank" class="link-linkedin">post</a>
                    </div>
                </div>
                <div class="tech-skills">
                    <span class="skill">Unity</span>
                    <span class="skill">C#</span>
                    <span class="skill">VR Development</span>
                    <span class="skill">Voice Analysis</span>
                    <span class="skill">Motion Tracking</span>
                </div>
                <div class="award">Georgetown University H2AI Hackathon: 1st Place Grand Prize & Patient Safety Award
                </div>
                <ul>
                    <li>Tackled the challenge of inconsistent Parkinson's symptom monitoring by engineering an
                        integrated VR healthcare system with voice analysis models trained on symptom patterns,
                        achieving 78% accuracy in fluctuation detection and enabling clinicians to make 40% more precise
                        medication adjustments during testing.</li>
                    <li>Addressed limitations of traditional clinical assessments by designing immersive VR-based
                        coordination measurement tools using Unity's physics engine and custom C# scripts, resulting in
                        92% accuracy compared to clinical standards while capturing 3x more granular data points for
                        comprehensive treatment planning.</li>
                    <li>Solved the problem of unexpected freezing episodes by creating 5 realistic VR training
                        environments that simulate challenging mobility scenarios (crowded spaces, narrow doorways,
                        complex turns), resulting in an 85% patient recognition rate of personal freezing triggers and a
                        32% reduction in reported falls during the evaluation period.</li>
                </ul>
            </div>

            <div class="project-item">
                <div class="proj-header">
                    <div class="proj-title">WALL-E</div>
                    <div class="proj-links">
                        <a href="https://github.com/mohamedshaik272/WALL-E" target="_blank"
                            class="link-github">github</a>
                        <a href="https://devpost.com/software/wall-e-9e2s8m" target="_blank"
                            class="link-devpost">devpost</a>
                        <a href="https://www.linkedin.com/feed/update/urn:li:activity:7251751559045287936/"
                            target="_blank" class="link-linkedin">post</a>
                    </div>
                </div>
                <div class="tech-skills">
                    <span class="skill">Python</span>
                    <span class="skill">React</span>
                    <span class="skill">GPT-4</span>
                    <span class="skill">PyQT5</span>
                    <span class="skill">JavaScript</span>
                    <span class="skill">OpenCV</span>
                    <span class="skill">Arduino</span>
                    <span class="skill">Raspberry Pi</span>
                </div>
                <div class="award">PatriotHacks 2024: Triple Winner (Patriot Favorite, Most Likely to be a Startup, Best
                    Cyberpunk Theme)</div>
                <ul>
                    <li>Addressed the growing problem of digital and physical clutter by architecting a dual-purpose AI
                        system with Python backend and React frontend, creating unified solutions that reduced
                        organization time by 65% and increased productivity for 18 test users who managed both digital
                        and physical spaces.</li>
                    <li>Solved file categorization challenges by implementing a GPT-4 powered analysis system using
                        custom prompting techniques and PyQT5 interfaces, achieving 95% classification accuracy across
                        12 document types and enabling users to locate files through natural language queries 8x faster
                        than manual search.</li>
                    <li>Tackled physical waste sorting inefficiencies by integrating YOLOv8 computer vision algorithms
                        with Arduino/Raspberry Pi hardware, creating a system that achieved 90% detection accuracy under
                        variable lighting conditions and automatically categorized household items for proper disposal,
                        reducing sorting errors by 78%.</li>
                </ul>
            </div>


            <div class="project-item">
                <div class="proj-header">
                    <div class="proj-title">Optimal Path Navigation</div>
                    <div class="proj-links">
                        <a href="https://github.com/mohamedshaik272/Optimal-Path-Navigation" target="_blank"
                            class="link-github">github</a>
                    </div>
                </div>
                <div class="tech-skills">
                    <span class="skill">Python</span>
                    <span class="skill">TensorFlow</span>
                    <span class="skill">Hugging Face</span>
                    <span class="skill">3D Mapping</span>
                    <span class="skill">Depth Estimation</span>
                </div>
                <ul>
                    <li>Confronted limitations of 2D navigation systems by pioneering a depth-based framework using
                        Python and custom TensorFlow models that converts standard camera images into detailed 3D point
                        clouds, generating over 500 unique environmental maps and improving navigation accuracy by 67%
                        in complex indoor and outdoor settings.</li>
                    <li>Addressed poor obstacle detection in varied lighting conditions by implementing sophisticated
                        image filtering and calibration techniques with adaptive thresholding algorithms, resulting in
                        87% improved detection accuracy in real-world testing environments and reducing navigation
                        errors by 42% compared to baseline systems.</li>
                    <li>Solved the high cost barrier of specialized hardware by optimizing system performance through
                        pre-trained Hugging Face models and efficient TensorFlow implementations, reducing
                        implementation costs by 85% (from $2,200 to $325) while maintaining 94% of the accuracy achieved
                        with dedicated LiDAR systems.</li>
                </ul>
            </div>

            <div class="project-item">
                <div class="proj-header">
                    <div class="proj-title">Peekabot</div>
                    <div class="proj-links">
                        <a href="https://github.com/mohamedshaik272/Peekabot" target="_blank"
                            class="link-github">github</a>
                        <a href="https://devpost.com/software/peekabot" target="_blank" class="link-devpost">devpost</a>
                        <a href="https://www.linkedin.com/feed/update/urn:li:activity:7246653833811038208/"
                            target="_blank" class="link-linkedin">post</a>
                    </div>
                </div>
                <div class="tech-skills">
                    <span class="skill">Python</span>
                    <span class="skill">OpenCV</span>
                    <span class="skill">Mediapipe</span>
                    <span class="skill">Arduino</span>
                    <span class="skill">Raspberry Pi</span>
                    <span class="skill">AWS IoT</span>
                    <span class="skill">Real-time Processing</span>
                </div>
                <div class="award">HackOverflow 2024: Best Robot Hack Winner</div>
                <ul>
                    <li>Addressed critical child safety monitoring challenges by developing a real-time system using
                        optimized OpenCV and Mediapipe algorithms on Raspberry Pi hardware, achieving 30 fps processing
                        with just 50ms latency and enabling detection of 15 different hazard types with 93% accuracy
                        before incidents occur.</li>
                    <li>Solved the conflict between timely alerts and data security by implementing an end-to-end
                        encrypted transmission pipeline through AWS IoT Core with custom middleware protocols,
                        delivering alerts in under 100ms while maintaining COPPA compliance and preventing unauthorized
                        access to sensitive monitoring data.</li>
                    <li>Tackled monitoring blind spots by designing an intelligent camera tracking system using Arduino
                        sensors and stepper motors controlled by custom Python scripts, creating a solution that
                        automatically adjusts positioning to follow children's movement and reducing uncovered areas by
                        96% compared to fixed-position monitoring systems.</li>
                </ul>
            </div>


            <div class="project-item">
                <div class="proj-header">
                    <div class="proj-title">NaviguideAI</div>
                    <div class="proj-links">
                        <a href="https://github.com/San68bot/NaviguideAI" target="_blank" class="link-github">github</a>
                        <a href="https://devpost.com/software/computer-vision-solutions" target="_blank"
                            class="link-devpost">devpost</a>
                        <a href="https://www.linkedin.com/feed/update/urn:li:activity:7117288751579439104/"
                            target="_blank" class="link-linkedin">post</a>
                    </div>
                </div>
                <div class="tech-skills">
                    <span class="skill">Java</span>
                    <span class="skill">Python</span>
                    <span class="skill">OpenCV</span>
                    <span class="skill">TensorFlow</span>
                    <span class="skill">CNN</span>
                    <span class="skill">Spatial Audio</span>
                    <span class="skill">Pathfinding Algorithms</span>
                </div>
                <div class="award">PatriotHacks 2023: Best AI-Powered Hack Winner</div>
                <ul>
                    <li>Identified accessibility gaps for visually impaired users by designing an assistive navigation
                        system using hybrid Java/Python architecture and TensorFlow models for environmental perception,
                        resulting in a wearable solution that increased independent navigation confidence by 76% during
                        user testing with 12 participants.</li>
                    <li>Addressed prohibitive costs of assistive tech by creating a spatial mapping solution using
                        monocular cameras with custom CNN-based depth estimation instead of LiDAR, achieving 92%
                        obstacle detection accuracy while reducing hardware costs from $2,100+ to just $129, making the
                        technology accessible to 5x more potential users.</li>
                    <li>Solved directional guidance challenges by engineering a multi-modal feedback system using
                        spatial audio processing algorithms and haptic signal generators, delivering real-time
                        directional cues with only 127ms latency and achieving 96% successful navigation rate through
                        complex test environments.</li>
                    <li>Tackled mobility-specific navigation needs by incorporating accessibility-focused pathfinding
                        algorithms with parametric priority weighting based on CDC guidelines, creating routes that
                        automatically prefer wider walkways and handrail proximity for users with mobility challenges
                        and reducing navigation stress scores by 44% in user surveys.</li>
                </ul>
            </div>
        </section>

        <footer>
            &copy; powered by monster energy drinks
        </footer>
    </div>
</body>

</html>